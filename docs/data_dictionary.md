# Data Dictionary

This document describes the JSON coordinate file format generated by the pose estimation pipeline.

---

## File Naming Convention

```
player{N}_part{M}_clip{K}_grade{G}.json
```

| Field   | Description                                        | Example |
|---------|----------------------------------------------------|---------|
| N       | Player identifier                                  | 10      |
| M       | Video part number (a player may have multiple sessions) | 1    |
| K       | Clip number within the part                        | 3       |
| G       | Quality grade assigned to the bandeja shot (1-10)  | 8       |

**Example**: `player10_part1_clip3_grade8.json`

---

## Grade Scale

Grades represent the quality of the bandeja movement technique, rated from 1 to 10. For LSTM classification, grades are grouped into 5 classes:

| Grade | Class | Label      | Description                                    |
|-------|-------|------------|------------------------------------------------|
| 1-2   | 0     | Very Low   | Very poor technique, major form issues         |
| 3-4   | 1     | Low        | Below average, several technique problems      |
| 5-6   | 2     | Medium     | Average technique, room for improvement        |
| 7-8   | 3     | High       | Good technique, minor adjustments needed       |
| 9-10  | 4     | Excellent  | Excellent technique, professional-level form   |

The mapping function is: `class = min((grade - 1) // 2, 4)`

---

## JSON Structure

Each coordinate file contains two main sections: **metadata** and **coordinate arrays**.

### Metadata Section

```json
{
  "metadata": {
    "video_path": "path/to/video.mp4",
    "video_name": "player10_part1_clip3_grade8",
    "player_id": 10,
    "part": 1,
    "clip": 3,
    "grade": 8,
    "duration": 3.0,
    "fps": 30.0,
    "frame_width": 1080,
    "frame_height": 1920,
    "total_frames": 90,
    "model": "mobilenet_thin",
    "resize": "0x0",
    "resize_out_ratio": 4.0,
    "reference_point": "Pelvis",
    "keypoints_used": ["Pelvis", "Left Shoulder", "Right Elbow", "Right Wrist"],
    "interpolation_method": "linear",
    "interpolated_frames": 5,
    "processing_date": "2026-02-20T19:12:51.358212"
  }
}
```

| Field                | Type    | Description                                                   |
|----------------------|---------|---------------------------------------------------------------|
| video_path           | string  | Path to the source video file                                 |
| video_name           | string  | Base name of the video (without extension)                    |
| player_id            | int     | Player identifier extracted from filename                     |
| part                 | int     | Video part number extracted from filename                     |
| clip                 | int     | Clip number extracted from filename                           |
| grade                | int     | Quality grade (1-10) extracted from filename                  |
| duration             | float   | Video duration in seconds                                     |
| fps                  | float   | Frames per second of the source video                         |
| frame_width          | int     | Video frame width in pixels                                   |
| frame_height         | int     | Video frame height in pixels                                  |
| total_frames         | int     | Total number of frames in the video                           |
| model                | string  | OpenPose model used (e.g., "mobilenet_thin")                  |
| resize               | string  | Input resize dimensions for OpenPose (e.g., "0x0" = default) |
| resize_out_ratio     | float   | Upsample ratio for OpenPose inference                         |
| reference_point      | string  | Body part used as origin for relative coordinates             |
| keypoints_used       | list    | List of body keypoints tracked                                |
| interpolation_method | string  | Method used to fill missing keypoints ("linear")              |
| interpolated_frames  | int     | Number of keypoint-frames that were interpolated              |
| processing_date      | string  | ISO 8601 timestamp of when the file was generated             |

### Coordinate Arrays

| Field                       | Type          | Description                                                        |
|-----------------------------|---------------|--------------------------------------------------------------------|
| Pelvis                      | list of [x,y] | Absolute pixel coordinates of the pelvis (MidHip)                  |
| Left Shoulder Original      | list of [x,y] | Absolute pixel coordinates of the left shoulder                    |
| Left Shoulder Relative      | list of [x,y] | Left shoulder coordinates relative to pelvis                       |
| Right Elbow Original        | list of [x,y] | Absolute pixel coordinates of the right elbow                      |
| Right Elbow Relative        | list of [x,y] | Right elbow coordinates relative to pelvis                         |
| Right Wrist Original        | list of [x,y] | Absolute pixel coordinates of the right wrist                      |
| Right Wrist Relative        | list of [x,y] | Right wrist coordinates relative to pelvis                         |
| timestamps                  | list of float | Timestamp in seconds for each valid frame                          |
| total_coordinates           | int           | Number of frames where the pelvis was detected                     |

---

## Coordinate System

- **Origin**: Top-left corner of the video frame (standard image coordinates).
- **Y-axis inversion**: The Y-axis is inverted during extraction so that positive Y points upward, matching the standard mathematical coordinate system. This means `y = (1 - original_y) * frame_height`.
- **Units**: Pixels (absolute coordinates) or pixel offsets (relative coordinates).

### Relative Coordinates

Pelvis-relative coordinates are computed for each keypoint as:
```
shoulder_relative = (shoulder_absolute_x - pelvis_x, shoulder_absolute_y - pelvis_y)
elbow_relative    = (elbow_absolute_x - pelvis_x, elbow_absolute_y - pelvis_y)
wrist_relative    = (wrist_absolute_x - pelvis_x, wrist_absolute_y - pelvis_y)
```

This removes the player's global position, isolating the arm movement pattern relative to the body center.

---

## Interpolation of Missing Keypoints

When OpenPose fails to detect a keypoint in a given frame, the system applies **linear interpolation** to fill in the missing values, provided that:

1. The **pelvis** was detected in that frame (pelvis is required; frames without pelvis are discarded entirely).
2. There are at least 2 valid detections of the missing keypoint across the clip (needed for interpolation).

Interpolation is applied **independently per keypoint and per axis** (X, Y). For example, if the shoulder is missing in frame 10 but detected in frames 8 and 12, its position at frame 10 is linearly interpolated between those two valid values.

The `interpolated_frames` metadata field counts the total number of keypoint-frame interpolations that were performed (e.g., if shoulder was interpolated in 3 frames and elbow in 2, the count is 5).

This approach produces more complete and continuous coordinate sequences for the LSTM model, compared to discarding frames with any missing keypoint.

---

## Valid Frame Criteria

A frame is included in the coordinate arrays if the **pelvis** is detected in that frame. Other keypoints (shoulder, elbow, wrist) that are missing in a frame are filled via interpolation rather than discarding the frame.

The `total_coordinates` field indicates how many frames had pelvis detection out of `total_frames`.

---

## OpenPose Keypoint Indices (Body-25 Model)

The following keypoint indices from the Body-25 model are used:

| Index | Body Part       | Variable Name in Config    |
|-------|-----------------|----------------------------|
| 8     | MidHip (Pelvis) | `KEYPOINT_PELVIS`          |
| 5     | Left Shoulder   | `KEYPOINT_LEFT_SHOULDER`   |
| 3     | Right Elbow     | `KEYPOINT_RIGHT_ELBOW`     |
| 4     | Right Wrist     | `KEYPOINT_RIGHT_WRIST`     |

### Human Selection Heuristic

When multiple humans are detected in a frame, the system selects the person with the **rightmost pelvis position** (largest X coordinate). This heuristic works because the camera is positioned to the left of the court, so the target player performing the bandeja is always the rightmost person in the frame.

### LSTM Feature Vector

Each frame produces 8 features for the LSTM model:

| Feature Index | Source                  | Description                        |
|---------------|-------------------------|------------------------------------|
| 0-1           | Pelvis (x, y)           | Absolute pelvis position           |
| 2-3           | Shoulder relative (x, y)| Left shoulder position relative to pelvis |
| 4-5           | Elbow relative (x, y)   | Right elbow position relative to pelvis  |
| 6-7           | Wrist relative (x, y)   | Right wrist position relative to pelvis  |

Sequences are padded or truncated to `MAX_SEQUENCE_LENGTH` (90) frames and independently normalized using per-clip zero-mean, unit-variance normalization.

### LSTM Classification

The model classifies clips into 5 quality classes (see Grade Scale above). Class weights are computed using `sklearn.utils.class_weight.compute_class_weight('balanced')` to handle class imbalance during training.
